{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0beb5fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proses pelabelan sentimen selesai.\n",
      "\n",
      "--- Hasil Pelabelan ---\n",
      "Contoh 5 data pertama yang sudah dilabeli:\n",
      "                                     stemmed_content sentiment_label\n",
      "0  ['sering', 'belanja', 'terus', 'aju', 'tidak',...         Negatif\n",
      "1   ['semenjak', 'upgrade', 'shopee', 'jadi', 'lot']         Negatif\n",
      "2          ['selesai', 'masalah', 'sangat', 'buruk']         Negatif\n",
      "3       ['apk', 'tidak', 'wajah', 'malaikat', 'jls']         Negatif\n",
      "4  ['lelet', 'stress', 'update', 'baru', 'tetap',...         Negatif\n",
      "\n",
      "Jumlah ulasan untuk setiap kategori sentimen:\n",
      "sentiment_label\n",
      "Netral     3137\n",
      "Positif    2932\n",
      "Negatif    2076\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_marketPlacesData.csv')\n",
    "\n",
    "# Lexicon Based Labeling\n",
    "positive_words = [\n",
    "    'suka', 'puas', 'bagus', 'cepat', 'rekomendasi', 'mantap', 'baik', 'terima', 'kasih', \n",
    "    'manfaat', 'senang', 'oke', 'ok', 'good', 'menyenangkan', 'solusi', 'mudah', 'bantu'\n",
    "]\n",
    "negative_words = [\n",
    "    'tidak', 'kecewa', 'buruk', 'lambat', 'masalah', 'jelek', 'lama', 'bohong', 'males', \n",
    "    'lemot', 'lot', 'uninstal', 'error', 'susah', 'rugi', 'lelet', 'parah', 'lag'\n",
    "]\n",
    "\n",
    "def assign_sentiment_label(text):\n",
    "    try:\n",
    "        word_list = eval(str(text))\n",
    "        if not isinstance(word_list, list):\n",
    "            word_list = []\n",
    "    except:\n",
    "        word_list = []\n",
    "\n",
    "    positive_score = sum(1 for word in word_list if word in positive_words)\n",
    "    negative_score = sum(1 for word in word_list if word in negative_words)\n",
    "\n",
    "    if positive_score > negative_score:\n",
    "        return 'Positif'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'Negatif'\n",
    "    else:\n",
    "        return 'Netral'\n",
    "\n",
    "df['sentiment_label'] = df['stemmed_content'].apply(assign_sentiment_label)\n",
    "\n",
    "print(\"\\nProses pelabelan sentimen selesai.\")\n",
    "\n",
    "print(\"\\n--- Hasil Pelabelan ---\")\n",
    "print(\"Contoh 5 data pertama yang sudah dilabeli:\")\n",
    "print(df[['stemmed_content', 'sentiment_label']].head())\n",
    "\n",
    "print(\"\\nJumlah ulasan untuk setiap kategori sentimen:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "\n",
    "output_filename = 'labeled_marketPlacesData.csv'\n",
    "df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12534f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil Pembagian Data ---\n",
      "Jumlah total data: 8145\n",
      "Jumlah data latih (train): 6516\n",
      "Jumlah data uji (test): 1629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('labeled_marketPlacesData.csv')\n",
    "\n",
    "X = df['stemmed_content']\n",
    "y = df['sentiment_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n--- Hasil Pembagian Data ---\")\n",
    "print(f\"Jumlah total data: {len(df)}\")\n",
    "print(f\"Jumlah data latih (train): {len(X_train)}\")\n",
    "print(f\"Jumlah data uji (test): {len(X_test)}\")\n",
    "\n",
    "train_data = pd.DataFrame({'stemmed_content': X_train, 'sentiment_label': y_train})\n",
    "test_data = pd.DataFrame({'stemmed_content': X_test, 'sentiment_label': y_test})\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "301ec089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil Ekstraksi Fitur TF-IDF ---\n",
      "Dimensi matriks TF-IDF data latih: (6516, 5939)\n",
      "Dimensi matriks TF-IDF data uji: (1629, 5939)\n",
      "\n",
      "Contoh 10 fitur (kata) pertama yang dipelajari dari data:\n",
      "['aa' 'aah' 'aamiin' 'aamiinn' 'aang' 'aaubuu' 'abad' 'abah' 'abai' 'abal']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "X_train = train_df['stemmed_content']\n",
    "y_train = train_df['sentiment_label']\n",
    "X_test = test_df['stemmed_content']\n",
    "y_test = test_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"\\n--- Hasil Ekstraksi Fitur TF-IDF ---\")\n",
    "print(f\"Dimensi matriks TF-IDF data latih: {X_train_tfidf.shape}\")\n",
    "print(f\"Dimensi matriks TF-IDF data uji: {X_test_tfidf.shape}\")\n",
    "\n",
    "print(\"\\nContoh 10 fitur (kata) pertama yang dipelajari dari data:\")\n",
    "print(vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff7f96dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi fitur TF-IDF selesai.\n",
      "\n",
      "--- Naive Bayes ---\n",
      "Akurasi: 0.7698\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.68      0.80      0.73       415\n",
      "      Netral       0.72      0.74      0.73       627\n",
      "     Positif       0.91      0.78      0.84       587\n",
      "\n",
      "    accuracy                           0.77      1629\n",
      "   macro avg       0.77      0.77      0.77      1629\n",
      "weighted avg       0.78      0.77      0.77      1629\n",
      "\n",
      "\n",
      "--- Decision Tree ---\n",
      "Akurasi: 0.9490\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.94      0.95      0.95       415\n",
      "      Netral       0.95      0.94      0.94       627\n",
      "     Positif       0.95      0.96      0.96       587\n",
      "\n",
      "    accuracy                           0.95      1629\n",
      "   macro avg       0.95      0.95      0.95      1629\n",
      "weighted avg       0.95      0.95      0.95      1629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "\n",
    "X_train = train_df['stemmed_content'].astype(str)\n",
    "y_train = train_df['sentiment_label']\n",
    "X_test = test_df['stemmed_content'].astype(str)\n",
    "y_test = test_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(\"Ekstraksi fitur TF-IDF selesai.\")\n",
    "\n",
    "print(\"\\n--- Naive Bayes ---\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Akurasi: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "\n",
    "print(\"\\n--- Decision Tree ---\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Akurasi: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "\n",
    "X_train = train_df['stemmed_content'].astype(str)\n",
    "y_train = train_df['sentiment_label']\n",
    "X_test = test_df['stemmed_content'].astype(str)\n",
    "y_test = test_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "print(\"Model selesai dilatih dan prediksi telah dibuat.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "# Plot untuk Naive Bayes\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb, labels=labels)\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Naive Bayes', fontsize=14)\n",
    "axes[0].set_xlabel('Prediksi', fontsize=12)\n",
    "axes[0].set_ylabel('Aktual', fontsize=12)\n",
    "\n",
    "# Plot untuk Decision Tree\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt, labels=labels)\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - Decision Tree', fontsize=14)\n",
    "axes[1].set_xlabel('Prediksi', fontsize=12)\n",
    "axes[1].set_ylabel('Aktual', fontsize=12)\n",
    "\n",
    "output_filename = 'confusion_matrices.png'\n",
    "plt.savefig(output_filename)\n",
    "\n",
    "print(f\"\\nVisualisasi confusion matrix telah disimpan sebagai '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "\n",
    "X_train = train_df['stemmed_content'].astype(str)\n",
    "y_train = train_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "print(\"Ekstraksi fitur TF-IDF selesai.\\n\")\n",
    "\n",
    "\n",
    "# --- TUNING UNTUK NAIVE BAYES ---\n",
    "print(\"--- [Mulai] Tuning Hyperparameter untuk Naive Bayes ---\")\n",
    "param_grid_nb = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\n--- Hasil Tuning Naive Bayes ---\")\n",
    "print(f\"Parameter Terbaik: {grid_search_nb.best_params_}\")\n",
    "print(f\"Skor Cross-Validation Terbaik: {grid_search_nb.best_score_:.4f}\\n\")\n",
    "\n",
    "\n",
    "# --- TUNING UNTUK DECISION TREE ---\n",
    "print(\"--- Tuning Hyperparameter untuk Decision Tree ---\")\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 20, 40],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_dt.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\n--- [Selesai] Hasil Tuning Decision Tree ---\")\n",
    "print(f\"Parameter Terbaik: {grid_search_dt.best_params_}\")\n",
    "print(f\"Skor Cross-Validation Terbaik: {grid_search_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "best_params_nb = {'alpha': 2.0}\n",
    "best_params_dt = {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "\n",
    "X_train = train_df['stemmed_content'].astype(str)\n",
    "y_train = train_df['sentiment_label']\n",
    "X_test = test_df['stemmed_content'].astype(str)\n",
    "y_test = test_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Model Final Naive Bayes\n",
    "final_nb_model = MultinomialNB(**best_params_nb)\n",
    "final_nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = final_nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nLaporan Klasifikasi Final: Naive Bayes (Tuned)\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Model Final Decision Tree\n",
    "final_dt_model = DecisionTreeClassifier(**best_params_dt, random_state=42)\n",
    "final_dt_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = final_dt_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nLaporan Klasifikasi Final: Decision Tree (Tuned)\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_params_nb = {'alpha': 2.0}\n",
    "best_params_dt = {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "X_train = train_df['stemmed_content'].astype(str)\n",
    "y_train = train_df['sentiment_label']\n",
    "X_test = test_df['stemmed_content'].astype(str)\n",
    "y_test = test_df['sentiment_label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "final_nb_model = MultinomialNB(**best_params_nb).fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = final_nb_model.predict(X_test_tfidf)\n",
    "\n",
    "final_dt_model = DecisionTreeClassifier(**best_params_dt, random_state=42).fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = final_dt_model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb, labels=labels)\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Naive Bayes (Tuned)', fontsize=16)\n",
    "axes[0].set_xlabel('Prediksi', fontsize=12)\n",
    "axes[0].set_ylabel('Aktual', fontsize=12)\n",
    "\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt, labels=labels)\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - Decision Tree (Tuned)', fontsize=16)\n",
    "axes[1].set_xlabel('Prediksi', fontsize=12)\n",
    "axes[1].set_ylabel('Aktual', fontsize=12)\n",
    "\n",
    "output_filename = 'final_tuned_confusion_matrices.png'\n",
    "plt.savefig(output_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f49d3a-ca28-4c2d-9ff0-1eb857fc52d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
