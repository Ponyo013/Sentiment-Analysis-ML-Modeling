{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da36311-0195-46e3-8651-5e6036851379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dataset has been created\n"
     ]
    }
   ],
   "source": [
    "# Combine the dataset\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"dataset/*.csv\")\n",
    "\n",
    "# Take only the content column\n",
    "all_data = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    if \"content\" in df.columns:\n",
    "        all_data.append(df[\"content\"])\n",
    "\n",
    "# Combine them into a one column\n",
    "combined = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save to new CSV\n",
    "combined.to_csv(\"marketPlacesData.csv\", index=False, header=[\"content\"])\n",
    "print(\"new dataset has been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea028fb4-782f-47e8-91e8-fd0c2b53708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>data_clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Udah sering belanja trs tapi setiap pengajuan ...</td>\n",
       "      <td>udah sering belanja trs tapi setiap pengajuan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semenjak di upgrade.. SHOPEE JADI LEMOT</td>\n",
       "      <td>semenjak di upgrade shopee jadi lemot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyelesaian masalah sangat buruk</td>\n",
       "      <td>penyelesaian masalah sangat buruk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apk enggaüòá jls</td>\n",
       "      <td>apk engga wajah malaikat jls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lelet stress. Udah update terbaru tetap aja lemot</td>\n",
       "      <td>lelet stress udah update terbaru tetap aja lemot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>Oke üëçüëçüëçüëç</td>\n",
       "      <td>oke jempol ke atas jempol ke atas jempol ke at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>Tokopedia memang ok</td>\n",
       "      <td>tokopedia memang ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>sangat membantu</td>\n",
       "      <td>sangat membantu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>tokopedia is the best</td>\n",
       "      <td>tokopedia is the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>mantap</td>\n",
       "      <td>mantap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     Udah sering belanja trs tapi setiap pengajuan ...   \n",
       "1               Semenjak di upgrade.. SHOPEE JADI LEMOT   \n",
       "2                     Penyelesaian masalah sangat buruk   \n",
       "3                                        Apk enggaüòá jls   \n",
       "4     Lelet stress. Udah update terbaru tetap aja lemot   \n",
       "...                                                 ...   \n",
       "8140                                           Oke üëçüëçüëçüëç   \n",
       "8141                                Tokopedia memang ok   \n",
       "8142                                    sangat membantu   \n",
       "8143                              tokopedia is the best   \n",
       "8144                                             mantap   \n",
       "\n",
       "                                     data_clean_content  \n",
       "0     udah sering belanja trs tapi setiap pengajuan ...  \n",
       "1                 semenjak di upgrade shopee jadi lemot  \n",
       "2                     penyelesaian masalah sangat buruk  \n",
       "3                          apk engga wajah malaikat jls  \n",
       "4      lelet stress udah update terbaru tetap aja lemot  \n",
       "...                                                 ...  \n",
       "8140  oke jempol ke atas jempol ke atas jempol ke at...  \n",
       "8141                                tokopedia memang ok  \n",
       "8142                                    sangat membantu  \n",
       "8143                              tokopedia is the best  \n",
       "8144                                             mantap  \n",
       "\n",
       "[8145 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from tabulate import tabulate\n",
    "\n",
    "df = pd.read_csv(\"marketPlacesData.csv\")\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert Emoji to Textual\n",
    "    text = emoji.demojize(text, language=\"id\")\n",
    "\n",
    "    # remove special character\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', ' ', text)\n",
    "\n",
    "    # remove number\n",
    "    text = re.sub(r'[0-9]+',' ', text)\n",
    "\n",
    "    # remove multiple spacing\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Case Folding \n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"data_clean_content\"] = df[\"content\"].apply(clean_text)\n",
    "df.to_csv(\"cleaned_marketPlacesData.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning Success\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7eefce-6439-4f67-bdde-edece7636d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slang Replacement Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_clean_content</th>\n",
       "      <th>slang_replacement_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udah sering belanja trs tapi setiap pengajuan ...</td>\n",
       "      <td>sudah sering belanja terus  tapi setiap pengaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semenjak di upgrade shopee jadi lemot</td>\n",
       "      <td>semenjak di upgrade shopee jadi lemot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penyelesaian masalah sangat buruk</td>\n",
       "      <td>penyelesaian masalah sangat buruk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apk engga wajah malaikat jls</td>\n",
       "      <td>apk tidak  wajah malaikat jls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lelet stress udah update terbaru tetap aja lemot</td>\n",
       "      <td>lelet stress sudah update terbaru tetap saja  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>oke jempol ke atas jempol ke atas jempol ke at...</td>\n",
       "      <td>oke jempol ke atas jempol ke atas jempol ke at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>tokopedia memang ok</td>\n",
       "      <td>tokopedia memang oke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>sangat membantu</td>\n",
       "      <td>sangat membantu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>tokopedia is the best</td>\n",
       "      <td>tokopedia is the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>mantap</td>\n",
       "      <td>mantap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     data_clean_content  \\\n",
       "0     udah sering belanja trs tapi setiap pengajuan ...   \n",
       "1                 semenjak di upgrade shopee jadi lemot   \n",
       "2                     penyelesaian masalah sangat buruk   \n",
       "3                          apk engga wajah malaikat jls   \n",
       "4      lelet stress udah update terbaru tetap aja lemot   \n",
       "...                                                 ...   \n",
       "8140  oke jempol ke atas jempol ke atas jempol ke at...   \n",
       "8141                                tokopedia memang ok   \n",
       "8142                                    sangat membantu   \n",
       "8143                              tokopedia is the best   \n",
       "8144                                             mantap   \n",
       "\n",
       "                              slang_replacement_content  \n",
       "0     sudah sering belanja terus  tapi setiap pengaj...  \n",
       "1                 semenjak di upgrade shopee jadi lemot  \n",
       "2                     penyelesaian masalah sangat buruk  \n",
       "3                         apk tidak  wajah malaikat jls  \n",
       "4     lelet stress sudah update terbaru tetap saja  ...  \n",
       "...                                                 ...  \n",
       "8140  oke jempol ke atas jempol ke atas jempol ke at...  \n",
       "8141                               tokopedia memang oke  \n",
       "8142                                    sangat membantu  \n",
       "8143                              tokopedia is the best  \n",
       "8144                                             mantap  \n",
       "\n",
       "[8145 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slang replacement\n",
    "\n",
    "# kamus bahasa gaul\n",
    "slang_df = pd.read_csv(\"cleaning/slang_indo.csv\")\n",
    "slang_dict = dict(zip(slang_df.iloc[:,0], slang_df.iloc[:,1]))\n",
    "\n",
    "def normalize_slang(text, slang_dict):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    \n",
    "    for w in words:\n",
    "        # cek apakah slang ada di kamus\n",
    "        if w in slang_dict:\n",
    "            new_words.append(slang_dict[w])\n",
    "        else:\n",
    "            new_words.append(w)\n",
    "    \n",
    "    return \" \".join(new_words)\n",
    "\n",
    "df = pd.read_csv(\"cleaned_marketPlacesData.csv\")\n",
    "df[\"slang_replacement_content\"] = df[\"data_clean_content\"].apply(lambda x: normalize_slang(str(x), slang_dict))\n",
    "df.to_csv(\"cleaned_marketPlacesData.csv\", index=False)\n",
    "\n",
    "print(\"Slang Replacement Success\")\n",
    "df[[\"data_clean_content\", \"slang_replacement_content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb5a0c2-c1d1-4085-9594-eb71b104d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slang_replacement_content</th>\n",
       "      <th>tokenized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudah sering belanja terus  tapi setiap pengaj...</td>\n",
       "      <td>[sudah, sering, belanja, terus, tapi, setiap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semenjak di upgrade shopee jadi lemot</td>\n",
       "      <td>[semenjak, di, upgrade, shopee, jadi, lemot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penyelesaian masalah sangat buruk</td>\n",
       "      <td>[penyelesaian, masalah, sangat, buruk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apk tidak  wajah malaikat jls</td>\n",
       "      <td>[apk, tidak, wajah, malaikat, jls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lelet stress sudah update terbaru tetap saja  ...</td>\n",
       "      <td>[lelet, stress, sudah, update, terbaru, tetap,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>oke jempol ke atas jempol ke atas jempol ke at...</td>\n",
       "      <td>[oke, jempol, ke, atas, jempol, ke, atas, jemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>tokopedia memang oke</td>\n",
       "      <td>[tokopedia, memang, oke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>sangat membantu</td>\n",
       "      <td>[sangat, membantu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>tokopedia is the best</td>\n",
       "      <td>[tokopedia, is, the, best]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>mantap</td>\n",
       "      <td>[mantap]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              slang_replacement_content  \\\n",
       "0     sudah sering belanja terus  tapi setiap pengaj...   \n",
       "1                 semenjak di upgrade shopee jadi lemot   \n",
       "2                     penyelesaian masalah sangat buruk   \n",
       "3                         apk tidak  wajah malaikat jls   \n",
       "4     lelet stress sudah update terbaru tetap saja  ...   \n",
       "...                                                 ...   \n",
       "8140  oke jempol ke atas jempol ke atas jempol ke at...   \n",
       "8141                               tokopedia memang oke   \n",
       "8142                                    sangat membantu   \n",
       "8143                              tokopedia is the best   \n",
       "8144                                             mantap   \n",
       "\n",
       "                                      tokenized_content  \n",
       "0     [sudah, sering, belanja, terus, tapi, setiap, ...  \n",
       "1          [semenjak, di, upgrade, shopee, jadi, lemot]  \n",
       "2                [penyelesaian, masalah, sangat, buruk]  \n",
       "3                    [apk, tidak, wajah, malaikat, jls]  \n",
       "4     [lelet, stress, sudah, update, terbaru, tetap,...  \n",
       "...                                                 ...  \n",
       "8140  [oke, jempol, ke, atas, jempol, ke, atas, jemp...  \n",
       "8141                           [tokopedia, memang, oke]  \n",
       "8142                                 [sangat, membantu]  \n",
       "8143                         [tokopedia, is, the, best]  \n",
       "8144                                           [mantap]  \n",
       "\n",
       "[8145 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "import nltk\n",
    "import ast\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.read_csv(\"cleaned_marketPlacesData.csv\")\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return word_tokenize(text)\n",
    "    return []\n",
    "\n",
    "df[\"tokenized_content\"] = df[\"slang_replacement_content\"].apply(tokenize_text)\n",
    "df.to_csv(\"cleaned_marketPlacesData.csv\", index=False)\n",
    "\n",
    "print(\"Tokenized Success\")\n",
    "df[[\"slang_replacement_content\", \"tokenized_content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c7c6a7-d868-410b-bba3-3dab29e035ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword removal Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>remove_stopwords_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sudah, sering, belanja, terus, tapi, setiap, ...</td>\n",
       "      <td>[sering, belanja, terus, pengajuan, tidak, lol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[semenjak, di, upgrade, shopee, jadi, lemot]</td>\n",
       "      <td>[semenjak, upgrade, shopee, jadi, lemot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[penyelesaian, masalah, sangat, buruk]</td>\n",
       "      <td>[penyelesaian, masalah, sangat, buruk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apk, tidak, wajah, malaikat, jls]</td>\n",
       "      <td>[apk, tidak, wajah, malaikat, jls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lelet, stress, sudah, update, terbaru, tetap,...</td>\n",
       "      <td>[lelet, stress, update, terbaru, tetap, lemot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>[oke, jempol, ke, atas, jempol, ke, atas, jemp...</td>\n",
       "      <td>[oke, jempol, atas, jempol, atas, jempol, atas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>[tokopedia, memang, oke]</td>\n",
       "      <td>[tokopedia, memang, oke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>[sangat, membantu]</td>\n",
       "      <td>[sangat, membantu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>[tokopedia, is, the, best]</td>\n",
       "      <td>[tokopedia, is, the, best]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>[mantap]</td>\n",
       "      <td>[mantap]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tokenized_content  \\\n",
       "0     [sudah, sering, belanja, terus, tapi, setiap, ...   \n",
       "1          [semenjak, di, upgrade, shopee, jadi, lemot]   \n",
       "2                [penyelesaian, masalah, sangat, buruk]   \n",
       "3                    [apk, tidak, wajah, malaikat, jls]   \n",
       "4     [lelet, stress, sudah, update, terbaru, tetap,...   \n",
       "...                                                 ...   \n",
       "8140  [oke, jempol, ke, atas, jempol, ke, atas, jemp...   \n",
       "8141                           [tokopedia, memang, oke]   \n",
       "8142                                 [sangat, membantu]   \n",
       "8143                         [tokopedia, is, the, best]   \n",
       "8144                                           [mantap]   \n",
       "\n",
       "                               remove_stopwords_content  \n",
       "0     [sering, belanja, terus, pengajuan, tidak, lol...  \n",
       "1              [semenjak, upgrade, shopee, jadi, lemot]  \n",
       "2                [penyelesaian, masalah, sangat, buruk]  \n",
       "3                    [apk, tidak, wajah, malaikat, jls]  \n",
       "4        [lelet, stress, update, terbaru, tetap, lemot]  \n",
       "...                                                 ...  \n",
       "8140  [oke, jempol, atas, jempol, atas, jempol, atas...  \n",
       "8141                           [tokopedia, memang, oke]  \n",
       "8142                                 [sangat, membantu]  \n",
       "8143                         [tokopedia, is, the, best]  \n",
       "8144                                           [mantap]  \n",
       "\n",
       "[8145 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop removal word\n",
    "\n",
    "import ast\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# inisial stopword remover\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "\n",
    "# Hapus kata negasi dari daftar stopwords\n",
    "negasi = [\"tidak\", \"nggak\", \"jangan\", \"belum\"]\n",
    "stopwords = [word for word in stopwords if word not in negasi]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in stopwords]\n",
    "\n",
    "df[\"remove_stopwords_content\"] = df[\"tokenized_content\"].apply(remove_stopwords)\n",
    "df.to_csv(\"cleaned_marketPlacesData.csv\", index=False)\n",
    "\n",
    "print(\"Stopword removal Success\")\n",
    "df[[\"tokenized_content\", \"remove_stopwords_content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afdd788-10f4-4b8a-a21d-05618b479064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengumpulkan kata unik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting terms: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8145/8145 [00:00<00:00, 243183.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melakukan stemming untuk semua kata unik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming terms: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8975/8975 [07:01<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remove_stopwords_content</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sering, belanja, terus, pengajuan, tidak, lol...</td>\n",
       "      <td>[sering, belanja, terus, aju, tidak, lolos, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[semenjak, upgrade, shopee, jadi, lemot]</td>\n",
       "      <td>[semenjak, upgrade, shopee, jadi, lot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[penyelesaian, masalah, sangat, buruk]</td>\n",
       "      <td>[selesai, masalah, sangat, buruk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apk, tidak, wajah, malaikat, jls]</td>\n",
       "      <td>[apk, tidak, wajah, malaikat, jls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lelet, stress, update, terbaru, tetap, lemot]</td>\n",
       "      <td>[lelet, stress, update, baru, tetap, lot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>[oke, jempol, atas, jempol, atas, jempol, atas...</td>\n",
       "      <td>[oke, jempol, atas, jempol, atas, jempol, atas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>[tokopedia, memang, oke]</td>\n",
       "      <td>[tokopedia, memang, oke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>[sangat, membantu]</td>\n",
       "      <td>[sangat, bantu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>[tokopedia, is, the, best]</td>\n",
       "      <td>[tokopedia, is, the, best]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>[mantap]</td>\n",
       "      <td>[mantap]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               remove_stopwords_content  \\\n",
       "0     [sering, belanja, terus, pengajuan, tidak, lol...   \n",
       "1              [semenjak, upgrade, shopee, jadi, lemot]   \n",
       "2                [penyelesaian, masalah, sangat, buruk]   \n",
       "3                    [apk, tidak, wajah, malaikat, jls]   \n",
       "4        [lelet, stress, update, terbaru, tetap, lemot]   \n",
       "...                                                 ...   \n",
       "8140  [oke, jempol, atas, jempol, atas, jempol, atas...   \n",
       "8141                           [tokopedia, memang, oke]   \n",
       "8142                                 [sangat, membantu]   \n",
       "8143                         [tokopedia, is, the, best]   \n",
       "8144                                           [mantap]   \n",
       "\n",
       "                                        stemmed_content  \n",
       "0     [sering, belanja, terus, aju, tidak, lolos, te...  \n",
       "1                [semenjak, upgrade, shopee, jadi, lot]  \n",
       "2                     [selesai, masalah, sangat, buruk]  \n",
       "3                    [apk, tidak, wajah, malaikat, jls]  \n",
       "4             [lelet, stress, update, baru, tetap, lot]  \n",
       "...                                                 ...  \n",
       "8140  [oke, jempol, atas, jempol, atas, jempol, atas...  \n",
       "8141                           [tokopedia, memang, oke]  \n",
       "8142                                    [sangat, bantu]  \n",
       "8143                         [tokopedia, is, the, best]  \n",
       "8144                                           [mantap]  \n",
       "\n",
       "[8145 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming - mengubah kata ke bentuk dasar\n",
    "\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm                  # progress bar\n",
    "from joblib import Parallel, delayed   # parallel processing\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(location='cachedir', verbose=0)\n",
    "\n",
    "# inisialisasi stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "@memory.cache\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "# Kumpulkan semua kata unik dari dataset\n",
    "print(\"Mengumpulkan kata unik\")\n",
    "unique_terms = set()\n",
    "for document in tqdm(df['remove_stopwords_content'], desc=\"Collecting terms\"):\n",
    "    if isinstance(document, str):\n",
    "        unique_terms.update(document.split())  \n",
    "    else:\n",
    "        unique_terms.update(document)          \n",
    "\n",
    "print(\"Melakukan stemming untuk semua kata unik\")\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(stemmed_wrapper)(term) for term in tqdm(unique_terms, desc=\"Stemming terms\")\n",
    ")\n",
    "\n",
    "# buat dictionary hasil stemming\n",
    "term_dict = dict(zip(unique_terms, results))\n",
    "\n",
    "# Fungsi untuk stemming setiap dokumen\n",
    "def stemmingText(document):\n",
    "    if isinstance(document, str):\n",
    "        terms = document.split()\n",
    "    else:\n",
    "        terms = document\n",
    "    return [term_dict[term] for term in terms]\n",
    "\n",
    "df[\"stemmed_content\"] = df[\"remove_stopwords_content\"].apply(stemmingText)\n",
    "df.to_csv(\"cleaned_marketPlacesData.csv\", index=False)\n",
    "\n",
    "print(\"Stemming successful\")\n",
    "df[[\"remove_stopwords_content\", \"stemmed_content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c10e1-96ad-4798-89af-e4c2f719a831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
